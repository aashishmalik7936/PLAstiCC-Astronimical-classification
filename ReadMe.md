This was a machine learning challenge hosted by kaggle in which I had to classify between different supernovas based on the 
provided information. You can follow this link for more information: https://www.kaggle.com/c/PLAsTiCC-2018

I finished on 113 (top 11%) rank out of 1094 participants worldwide.

                   ############################################ Challenge #######################################

The challenge was that the training data was very less and has only 7848 rows so, it was very easy to overfit the data. Feature selection 
was key in this competition.

                 ######################################## Approach #################################################

I did some EDA to become familiar with the featurs that are provided and tried to find some hidden information by plotting some
bubble, bar and line plots.

Tried to find outliers by using **mean +- 3 standard deviation** but couldn't find any.

Then, I did some preprocessing like filling the null values, transforming categorical columns using pandas dummies. Since I was training
the data on lightgbm model so, I didn't required to do feature scaling.

Now, make full use of lightgbm I used scikit optimzation algorithm to get the best set of parameters and trained my model with **stratified 5 fold CV** on them for the best possible accuracy I can get. 

I used stratified CV to ensure that each fold has the same ratio of target classes.

After this, I plotted the features importance graph to know the features that were very important for my lgbm model. I started feature 
engineering with most important features.

As the training data was very less, So I decided check to every feature that I generated by checking it on CV and sometimes on public 
leaderboard too. I removed those features from my dataset which were either giving a lot of boost the CV or decreaing the accuracy.

I generated around 115 new useful features.

I trained a xgboost model & a lgbm model on 12 fold CV and took the average for the best submission.

For test set, I did the prediction in chunks because the data was very huge and showing out of memory when I was loading the data 
altogether.

            ################################### What more could have been done #######################################

I was more dependent on boosting models and totally ignored linear models which could have been helpfull in belnding as they create more
diversity in the model.

I could have use out of fold predictions to train a 2nd level model or meta model in stacking.

A decent nn model could have been made too for blending. I tried to make a good nn model but due to lack to time I couldn't.
