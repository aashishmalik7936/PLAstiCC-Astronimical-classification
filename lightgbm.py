# -*- coding: utf-8 -*-
"""lightgbm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iKlXn99P1pGqiZgX2Lt4AjxifBGyRHRj
"""

import sys, os
import argparse
import time
from datetime import datetime as dt
import gc; gc.enable()

from sklearn.model_selection import StratifiedKFold
from tsfresh.feature_extraction import extract_features
from lightgbm import LGBMClassifier

def main(argc, argv):
    # Features to compute with tsfresh library. Fft coefficient is meant to capture periodicity    
    
    # agg features
    aggs = {
        'flux': ['min', 'max', 'mean', 'median', 'std', 'skew'],
        'flux_err': ['min', 'max', 'mean', 'median', 'std', 'skew'],
        'detected': ['mean'],
        'flux_ratio_sq':['sum', 'skew'],
        'flux_by_flux_ratio_sq':['sum','skew'],
        'flux_det_pass_0-wise':['sum','skew'],
        'flux_det_pass_1-wise':['sum','skew'],
        'flux_det_pass_2-wise':['sum','skew'],
        'flux_det_pass_3-wise':['sum','skew'],
        'flux_det_pass_4-wise':['sum','skew'],
        'flux_det_pass_5-wise':['sum','skew'],
        'flux_det':['sum','skew'],
        'flux_err_det':['sum','skew'],
        'flux_ratio':['sum','skew'],
        'flux_by_flux_ratio':['sum','skew'],
        'flux_ratio_det_pass_0-wise':['sum','skew'],
        'flux_ratio_det_pass_1-wise':['sum','skew'],
        'flux_ratio_det_pass_2-wise':['sum','skew'],
        'flux_ratio_det_pass_3-wise':['sum','skew'],
        'flux_ratio_det_pass_4-wise':['sum','skew'],
        'flux_ratio_det_pass_5-wise':['sum','skew'],
        'flux_ratio_pass_0-wise':['sum','skew'],
        'flux_ratio_pass_1-wise':['sum','skew'],
        'flux_ratio_pass_2-wise':['sum','skew'],
        'flux_ratio_pass_3-wise':['sum','skew'],
        'flux_ratio_pass_4-wise':['sum','skew'],
        'flux_ratio_pass_5-wise':['sum','skew'],
        'mjd_det_pass_0-wise':['sum'],
        'mjd_det_pass_1-wise':['sum'],
        'mjd_det_pass_2-wise':['sum'],
        'mjd_det_pass_3-wise':['sum'],
        'mjd_det_pass_4-wise':['sum'],
        'mjd_det_pass_5-wise':['sum'],
        'mjd':['mean'],
        'relative_flux':['mean']
    }
    
    # tsfresh features
    fcp = {
        'flux': {
            'longest_strike_above_mean': None,
            'longest_strike_below_mean': None,
            'mean_change': None,
            'mean_abs_change': None,
            'length': None,
        },
                
        'flux_by_flux_ratio_sq': {
            'longest_strike_above_mean': None,
            'longest_strike_below_mean': None,       
        },
                
        'flux_passband': {
            'fft_coefficient': [
                    {'coeff': 0, 'attr': 'abs'}, 
                    {'coeff': 1, 'attr': 'abs'}
                ],
            'kurtosis' : None, 
            'skewness' : None,
        },
                
        'mjd': {
            'maximum': None, 
            'minimum': None,
            'mean_change': None,
            'mean_abs_change': None,
        },
    }

    best_params = {
            'device': 'cpu', 
            'objective': 'multiclass', 
            'num_class': 14, 
            'boosting_type': 'gbdt', 
            'n_jobs': -1, 
            'max_depth': 7, 
            'n_estimators': 500, 
            'subsample_freq': 2, 
            'subsample_for_bin': 5000, 
            'min_data_per_group': 100, 
            'max_cat_to_onehot': 4, 
            'cat_l2': 1.0, 
            'cat_smooth': 59.5, 
            'max_cat_threshold': 32, 
            'metric_freq': 10, 
            'verbosity': -1, 
            'metric': 'multi_logloss', 
            'xgboost_dart_mode': False, 
            'uniform_drop': False, 
            'colsample_bytree': 0.5, 
            'drop_rate': 0.173, 
            'learning_rate': 0.0267, 
            'max_drop': 5, 
            'min_child_samples': 10, 
            'min_child_weight': 100.0, 
            'min_split_gain': 0.1, 
            'num_leaves': 7, 
            'reg_alpha': 0.1, 
            'reg_lambda': 0.00023, 
            'skip_drop': 0.44, 
            'subsample': 0.75}

    meta_train = process_meta('../input/PLAsTiCC-2018/training_set_metadata.csv')
    
    train = pd.read_csv('../input/PLAsTiCC-2018/training_set.csv')
    full_train = featurize(train, meta_train, aggs, fcp)

    if 'target' in full_train:
        y = full_train['target']
        del full_train['target']
        
    classes = sorted(y.unique())    
    class_weights = {c: 1 for c in classes}
    class_weights.update({c:2 for c in [64, 15]})
    print('Unique classes : {}, {}'.format(len(classes), classes))
    print(class_weights)
    #sanity check: classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]
    #sanity check: class_weights = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}
    #if len(np.unique(y_true)) > 14:
    #    classes.append(99)
    #    class_weights[99] = 2
    
    if 'object_id' in full_train:
        oof_df = full_train[['object_id']]
        del full_train['object_id'] 
        del full_train['hostgal_specz']
        del full_train['ra'], full_train['decl'], full_train['gal_l'], full_train['gal_b']
        del full_train['ddf']
    
    pd.set_option('display.max_rows', 500)
    print(full_train.describe().T)
    full_train['flux_per_time_det_photoz']=(full_train['flux_det_sum'].values/full_train['mjd_diff_det'].values)*np.square(full_train['hostgal_photoz'].values)
    full_train['flux_err_per_time_det_photoz']=(full_train['flux_err_det_sum'].values/full_train['mjd_diff_det'].values)*np.square(full_train['hostgal_photoz'].values)
    full_train['flux_det_pass_0_per_time_photoz']=(full_train['flux_det_pass_0-wise_sum'].values/full_train['mjd_det_pass_0-wise_sum'].values)*np.square(full_train['hostgal_photoz'].values)
    full_train['flux_det_pass_1_per_time_photoz']=(full_train['flux_det_pass_1-wise_sum'].values/full_train['mjd_det_pass_1-wise_sum'].values)*np.square(full_train['hostgal_photoz'].values)
    full_train['flux_det_pass_2_per_time_photoz']=(full_train['flux_det_pass_2-wise_sum'].values/full_train['mjd_det_pass_2-wise_sum'].values)*np.square(full_train['hostgal_photoz'].values)
    full_train['flux_det_pass_3_per_time_photoz']=(full_train['flux_det_pass_3-wise_sum'].values/full_train['mjd_det_pass_3-wise_sum'].values)*np.square(full_train['hostgal_photoz'].values)
    full_train['flux_det_pass_4_per_time_photoz']=(full_train['flux_det_pass_4-wise_sum'].values/full_train['mjd_det_pass_4-wise_sum'].values)*np.square(full_train['hostgal_photoz'].values)
    full_train['flux_det_pass_5_per_time_photoz']=(full_train['flux_det_pass_5-wise_sum'].values/full_train['mjd_det_pass_5-wise_sum'].values)*np.square(full_train['hostgal_photoz'].values)
    
    full_train['distance']=full_train['hostgal_photoz'].values*full_train['mjd_mean'].values
    full_train['new_flux']=1/(full_train['distmod']**2)
         
    full_train['flux_amp_photoz'] = ((full_train['flux_max'].values-full_train['flux_min'].values)/full_train['flux_mean'].values)*np.square(full_train['hostgal_photoz'].values)
    trainingDartDf=pd.DataFrame()
    for column in columnsToAdd:
        trainingDartDf[column]=trainingJimsDf.loc[:,column]
    full_train=pd.concat([full_train, trainingDartDf], axis=1)
    full_train.fillna(-99999, inplace=True)
    del full_train['mjd_mean'], full_train['distmod']
    print('shape:',full_train.shape)

    eval_func = partial(lgbm_modeling_cross_validation, 
                        full_train=full_train, 
                        y=y, 
                        classes=classes, 
                        class_weights=class_weights, 
                        nr_fold=12, 
                        random_state=30)

    best_params.update({'n_estimators': 1100})
    
    # modeling from CV
    clfs, score = eval_func(best_params)
        
    filename = 'subm_{:.6f}_{}.csv'.format(score, 
                     dt.now().strftime('%Y-%m-%d-%H-%M'))
    print('save to {}'.format(filename))
    # TEST
    z=process_test(clfs, 
                 features=full_train.columns, 
                 featurize_configs={'aggs': aggs, 'fcp': fcp}, 
                 train_mean=train_mean, 
                 filename=filename,
                 chunks=4600000)
        
    print("Shape BEFORE grouping: {}".format(z.shape))
    z = z.groupby('object_id').mean()
    print("Shape AFTER grouping: {}".format(z.shape))
    return z.to_csv('single_{}'.format(filename), index=True)


if __name__ == '__main__':
    main(len(sys.argv), sys.argv)